using Random, Plots, CSV, DataFrames
pyplot()
push!(LOAD_PATH, pwd())
using AgentTree

#agent = buildAgent(2,TM=true,hm=true)

############# Plot values of an agent throughout an epoch #######################################
function plotSim(f::Function; data::Union{AbstractArray,Nothing}=Nothing(), ana::Union{Matrix,Bool}=false, N::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    if typeof(data) != Nothing
        N = length(data[:,1])
    end
    Model = f(n=N,data=data,Î±=Î±,Î¸=Î¸)
    plt_Q,bar_Q,plt_T,bar_T,plt_h,bar_h,plt_arb = Nothing(),Nothing(),Nothing(),Nothing(),Nothing(),Nothing(),Nothing()
    m = "$f"[4:end]

    if Model[2] != nothing
        if ana == true
            anaQ = zeros(8,N)
            for i=1:N-1
                anaQ[1,i+1] = (1-Î±)*anaQ[1,i] + Î±*(0.7*anaQ[3,i]+0.3*anaQ[4,i])
                anaQ[2,i+1] = (1-Î±)*anaQ[2,i] + Î±*(0.3*anaQ[3,i]+0.7*anaQ[4,i])
                anaQ[3,i+1] = (1-Î±)*anaQ[3,i] + Î±*(findmax([anaQ[5,i] anaQ[6,i]])[1])
                anaQ[4,i+1] = (1-Î±)*anaQ[4,i] + Î±*(findmax([anaQ[7,i] anaQ[8,i]])[1])
                anaQ[5,i+1] = (1-Î±)*anaQ[5,i] + Î±*0.8
                anaQ[6,i+1] = (1-Î±)*anaQ[6,i] + Î±*0.0
                anaQ[7,i+1] = (1-Î±)*anaQ[7,i] + Î±*0.2
                anaQ[8,i+1] = (1-Î±)*anaQ[8,i] + Î±*0.0
            end
        elseif typeof(ana) == Matrix{Float64}
            anaQ = zeros(8,N)
            anaQ[5:8,:] = ana'
            for i=1:N-1
                anaQ[1,i+1] = (1-Î±)*anaQ[1,i] + Î±*(0.7*anaQ[3,i]+0.3*anaQ[4,i])
                anaQ[2,i+1] = (1-Î±)*anaQ[2,i] + Î±*(0.3*anaQ[3,i]+0.7*anaQ[4,i])
                anaQ[3,i+1] = (1-Î±)*anaQ[3,i] + Î±*(findmax([anaQ[5,i] anaQ[6,i]])[1])
                anaQ[4,i+1] = (1-Î±)*anaQ[4,i] + Î±*(findmax([anaQ[7,i] anaQ[8,i]])[1])
            end
        else
            anaQ = zeros(4,N)
        end

        plt_Q = plot(Model[2][1,:],label="Î¾.A1",color="blue",ylims = (0, 1))
        plot!(Model[2][2,:],label="Î¾.A2",color="orange")
        #plot!(Model[2][3,:],label="Î¼.A1",color="green")
        #plot!(Model[2][4,:],label="Î¼.A2")
        #plot!(Model[2][5,:],label="Î½.A1",color="magenta")
        #plot!(Model[2][6,:],label="Î½.A2")
        plot!(anaQ[1,:],label="Analytic Î¾.A1",color="blue",linestyle=:dash)
        plot!(anaQ[2,:],label="Analytic Î¾.A2",color="orange",linestyle=:dash)
        #plot!(anaQ[3,:],label="Analytic Î¼.A1",color="green",linestyle=:dash)
        #plot!(anaQ[4,:],label="Analytic Î½.A1",color="magenta",linestyle=:dash)

        title!("$m Time Series of Q values")
        xaxis!("Number of iterations")
        yaxis!("Q(s,a)")

        bar_Q = bar([Model[1].state.Q.A1, Model[1].state.Q.A2, Model[1].Î¼.state.Q.A1, Model[1].Î¼.state.Q.A2, Model[1].Î½.state.Q.A1, Model[1].Î½.state.Q.A2],legend=false,ylims = (0, 1));
        title!("$m Final Q values")
        xaxis!("Action(s) Taken")
        xticks!((1:6),["Î¾.A1", "Î¾.A2", "Î¼.A1", "Î¼.A2", "Î½.A1", "Î½.A2"])
        yaxis!("Q(s,a)")
    end

    if Model[1].state.T != nothing

        plt_T = plot(Model[3][1,:],label="Î¾.A1",color="blue",ylims = (0, 1))
        plot!(Model[3][2,:],label="Î¾.A2",color="orange")
        plot!(Model[3][3,:],label="Î¼.A1",color="green")
        plot!(Model[3][4,:],label="Î¼.A2")
        plot!(Model[3][5,:],label="Î½.A1",color="magenta")
        plot!(Model[3][6,:],label="Î½.A2")
        title!("$m Time Series of Transition Model")

        xaxis!("Number of iterations")
        yaxis!("T(s,a,s')")

        bar_T = bar([Model[1].state.T.A1, Model[1].state.T.A2, Model[1].Î¼.state.T.A1, Model[1].Î¼.state.T.A2, Model[1].Î½.state.T.A1, Model[1].Î½.state.T.A2],legend=false,ylims = (0, 1));
        title!("$m Final Transition Model")
        xaxis!("Action(s) Taken")
        xticks!((1:6),["Î¾.A1", "Î¾.A2", "Î¼.A1", "Î¼.A2", "Î½.A1", "Î½.A2"])
        yaxis!("T(s,a,s')")
    end

    if Model[4] != nothing
        plt_h = plot(Model[4][1,:],label="Î¾.A1",color="blue",ylims = (0, 1))
        plot!(Model[4][2,:],label="Î¾.A2",color="orange")
        plot!(Model[4][3,:],label="Î¼.A1",color="green")
        plot!(Model[4][4,:],label="Î¼.A2")
        plot!(Model[4][5,:],label="Î½.A1",color="magenta")
        plot!(Model[4][6,:],label="Î½.A2")

        title!("$m Time Series of values")
        xaxis!("Number of iterations")
        yaxis!("h(s,a)")

        bar_h = bar([Model[1].state.h.A1, Model[1].state.h.A2, Model[1].Î¼.state.h.A1, Model[1].Î¼.state.h.A2, Model[1].Î½.state.h.A1, Model[1].Î½.state.h.A2],legend=false,ylims = (0, 1));
        title!("$m Final Habit values")
        xaxis!("Action(s) Taken")
        xticks!((1:6),["Î¾.A1", "Î¾.A2", "Î¼.A1", "Î¼.A2", "Î½.A1", "Î½.A2"])
        yaxis!("h(s,a)")
    end
    if Model[1].state.T != nothing && Model[4] != nothing
        plt_arb = plot(Model[5],ylims = (0, 1))
        title!("Probability over time of Goal Directed Controller being chosen")
        xaxis!("Number of iterations")
        yaxis!("Probability of Goal Directed Controller being chosen")
    end

    return Model,plt_Q,bar_Q,plt_T,bar_T,plt_h,bar_h,plt_arb,anaQ
end

function plotData(exData::AbstractArray,exRwdProb::AbstractArray; Î±::Float64=0.5, Î¸::Float64=5.0)
    habitSimResults = plotSim(runHabit,data=exData,ana=exRwdProb,Î±=Î±)
    MFSimResults = plotSim(runMF,data=exData,ana=exRwdProb,Î±=Î±)
    MBSimResults = plotSim(runMB,data=exData,ana=exRwdProb,Î±=Î±)
    GDSimResults = plotSim(runGD,data=exData,ana=exRwdProb,Î±=Î±)
    HWVSimResults = plotSim(runHWV,data=exData,ana=exRwdProb,Î±=Î±)

    plth = habitSimResults[2]
    pltf = MFSimResults[2]
    pltb = MBSimResults[2]
    pltg = GDSimResults[2]
    pltw = HWVSimResults[2]

    pltQ = plot(plth,pltf,pltb,pltg,pltw,size=(1000,600),legend=false)

    pltb = MBSimResults[4]
    pltg = GDSimResults[4]
    pltw = HWVSimResults[4]

    pltT = plot(pltb,pltg,pltw,size=(1000,600))

    plth = habitSimResults[6]
    pltw = HWVSimResults[6]

    pltH = plot(plth,pltw,size=(1000,600))

    return pltQ, pltT, pltH
end

######### Run/Plot all Raw controllers for a full epoch ############################################
function runAllRaw(; n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )

    habit = runHabit(N=n,Î±=Î±,Î¸=Î¸)
    MF = runMF(N=n,Î±=Î±,Î¸=Î¸)
    MB = runMB(N=n,Î±=Î±,Î¸=Î¸)

    return habit, MF, MB
end

function plotAllRaw(; n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    ## Raw Models
    habit = plotSim(runHabit,N=n,Î±=Î±,Î¸=Î¸)
    MF = plotSim(runMF,N=n,Î±=Î±,Î¸=Î¸)
    MB = plotSim(runMB,N=n,Î±=Î±,Î¸=Î¸)

    return habit, MF, MB
end

######### Run/Plot all Blend controllers for a full epoch ##########################################
function runAllBlend(; n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )

    GD = runGD(N=n,Î±=Î±,Î¸=Î¸)
    HWV = runHWV(N=n,Î±=Î±,Î¸=Î¸)

    return GD, HWV
end

function plotAllBlend(; n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    GD = plotSim(runGD,N=n,Î±=Î±,Î¸=Î¸)
    HWV = plotSim(runHWV,N=n,Î±=Î±,Î¸=Î¸)

    return GD, HWV
end

################## Misc Functions ##################################################################
function softMax(A; Î¸::Float64=5.0)
    a_idx = findall(x->x==findmax(A)[1], A)[1]
    a = A[a_idx][1]
    p = exp(Î¸*a)/sum(exp.(Î¸*A))
    return p, a_idx
end

function rwd(p)
    if rand() < p
        return 1.0
    else
        return 0.0
    end
end

################### Agent Value Updates ############################################################
function habitUpdate(h::Actions,actn::String,Î±::Float64)

    if actn == "A1"
        h.A1 = (1-Î±)*h.A1 + Î±
        h.A2 = (1-Î±)*h.A2
    elseif actn == "A2"
        h.A1 = (1-Î±)*h.A1
        h.A2 = (1-Î±)*h.A2 + Î±
    else
        throw(ArgumentError("Action argument must be either \"A1\" or \"A2\""))
    end
    return h
end

function QUpdate(Node::DecisionTree, actn::String, Î¼::Union{Bool,Nothing}, Î±::Float64)

    if Node.state.name == "Î¾"
        Î¼ ? Q_ = findmax([Node.Î¼.state.Q.A1, Node.Î¼.state.Q.A2])[1] : Q_ = findmax([Node.Î½.state.Q.A1, Node.Î½.state.Q.A2])[1]
    elseif Node.state.name == "Î¼" || Node.state.name == "Î½"
        Q_ = Node.state.R
    else
        throw(error("unrecognised state"))
    end

    if actn == "A1"
        Node.state.Q.A1 = (1-Î±)*Node.state.Q.A1 + Î±*Q_
    elseif actn == "A2"
        Node.state.Q.A2 = (1-Î±)*Node.state.Q.A2 + Î±*Q_
    else
        throw(ArgumentError("action argument must be either \"A1\" or \"A2\""))
    end

    return Node.state.Q
end

function modelledQUpdate(Node::DecisionTree, actn::String, Î¼::Union{Bool,Nothing}, Î±::Float64)

    if Node.state.name == "Î¾"       # if in base node Qlearn Eq is updated by Qvalue of
                                    # state landed in as R:=0 in this state
        actn == "A1" ? (p = Node.state.T.A1 ; q = 1-(Node.state.T.A1)) : (p = 1-(Node.state.T.A2) ; q = Node.state.T.A2)           # selecting rare and common transition Probabilities
                Q_ = p*findmax([Node.Î¼.state.Q.A1, Node.Î¼.state.Q.A2])[1] + q*findmax([Node.Î½.state.Q.A1,Node.Î½.state.Q.A2])[1] # max action * T
        if Î¼ #actn == "A1" #Î¼
            Node.state.Q.A1 = (1-Î±)*Node.state.Q.A1 + Î±*Q_
        else
            Node.state.Q.A2 = (1-Î±)*Node.state.Q.A2 + Î±*Q_
        end
    elseif Node.state.name == "Î¼" || Node.state.name == "Î½"

        Q_ = Node.state.R
        if actn == "A1"
            Node.state.Q.A1 = (1-Î±)*Node.state.Q.A1 + Î±*Q_
        else
            Node.state.Q.A2 = (1-Î±)*Node.state.Q.A2 + Î±*Q_
        end
    else
        throw(error("unrecognised state"))
    end

    return Node.state.Q
end

function transitionUpdate(Node::DecisionTree,actn::String,Î¼::Union{Bool,Nothing},Î±::Float64)
    if Node.state.name == "Î¾"
        Î¼ ? (actn == "A1" ? Node.state.T.A1 = (1-Î±)*Node.state.T.A1 + Î± : Node.state.T.A2 = (1-Î±)*Node.state.T.A2) : (actn == "A1" ? Node.state.T.A1 = (1-Î±)*Node.state.T.A1 : Node.state.T.A2 = (1-Î±)*Node.state.T.A2 + Î±)
    elseif Node.state.name == "Î¼" || Node.state.name == "Î½"
        if actn == "A1"
            Node.state.T.A1 = (1-Î±)*Node.state.T.A1 + Î±
        elseif actn == "A2"
            Node.state.T.A2 = (1-Î±)*Node.state.T.A2 + Î±
        end
    else
        throw(error("unrecognised state"))
    end

    return Node.state.T
end

################### Environment ####################################################################
function taskEval(state::String,actn::String)
    if state == "Î¾"
        actn == "A1" ? (rand() < 0.7 ? Î¼ = true : Î¼ = false) : (rand() < 0.7 ? Î¼ = false : Î¼ = true)
        R = 0.0
    elseif state == "Î¼"
        Î¼ = Nothing()
        actn == "A1" ? R = rwd(0.8) : R = rwd(0.0)
    elseif state == "Î½"
        Î¼ = Nothing()
        actn == "A1" ? R = rwd(0.2) : R = rwd(0.0)
    end

    return Î¼, R
end

function taskRead(state::String,data::AbstractArray)
    if state == "Î¾"
        data[1] ? (data[2] ? Î¼ = false : Î¼ = true) : (data[2] ? Î¼ = true : Î¼ = false)
        R = 0.0
    else
        Î¼ = Nothing()
        R = Int(data[2])
    end

    return Î¼, R
end

function taskCreateData(agent::DecisionTree;N::Int=150,Î±::Float64=0.5,Î¸::Float64=5.0)
    dat = Array{Any,2}(undef,(N,4))
    for i = 1:N
        x = MFCtrl(agent,Î±=Î±,Î¸=Î¸)
        dat[i,:] = [x[3][1] x[3][2] x[3][3] x[2]]
    end
    Data = [[d=="A1" for d in dat[:,1]] [d for d in dat[:,2]] [d=="A1" for d in dat[:,3]] [d==1.0 for d in dat[:,4]]]

    return Data
end

# test = taskCreateData(agent)
#
# test[:,4]

################### Agent Controllers ##############################################################

function habitFlatCtrl(Node::DecisionTree; data::Union{AbstractArray,Nothing}=Nothing(), Î¸::Float64=5.0)

    if typeof(Node.state.h) == Nothing
        throw(error("Agent must have habitual modelling enabled, set kwarg \"hm=true\" when created"))
    end

    Î±=1.0
    if typeof(data) == Nothing
        Ï€, a_idx = softMax([Node.state.h.A1, Node.state.h.A2],Î¸=Î¸)
        rv = rand()
        ((Ï€ >= rv && a_idx == 1) || (Ï€ < rv && a_idx == 2)) ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskEval(Node.state.name,actn)

        if Node.state.name == "Î¾"
            Î¼ ? habitCtrl(Node.Î¼,Î±=Î±) : habitCtrl(Node.Î½,Î±=Î±)
        end
    else
        data[1] ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskRead(Node.state.name,data[1:2])

        if Node.state.name == "Î¾"
            Î¼ ? habitCtrl(Node.Î¼,data=data[3:4],Î±=Î±) : habitCtrl(Node.Î½,data=data[3:4],Î±=Î±)
        end
    end

    Node.state.R = Rwd
    Node.state.h = habitUpdate(Node.state.h,actn,Î±)
    Node.state.Q = QUpdate(Node,actn,Î¼,Î±)

    return Node, Rwd
end

function habitCtrl(Node::DecisionTree; data::Union{AbstractArray,Nothing}=Nothing(), Î±::Float64=0.5,Î¸::Float64=5.0)

    if typeof(Node.state.h) == Nothing
        throw(error("Agent must have habitual modelling enabled, set kwarg \"hm=true\" when created"))
    end

    if typeof(data) == Nothing
        Ï€, a_idx = softMax([Node.state.h.A1, Node.state.h.A2],Î¸=Î¸)
        rv = rand()
        ((Ï€ >= rv && a_idx == 1) || (Ï€ < rv && a_idx == 2)) ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskEval(Node.state.name,actn)
        Node.state.R = Rwd
        Node.state.h = habitUpdate(Node.state.h,actn,Î±)
        #Node.state.Q = QUpdate(Node,actn,Î¼,Î±)
        if Node.state.name == "Î¾"
            Î¼ ? habitCtrl(Node.Î¼,Î±=Î±) : habitCtrl(Node.Î½,Î±=Î±)

        end

    else
        data[1] ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskRead(Node.state.name,data[1:2])
        Node.state.R = Rwd
        Node.state.h = habitUpdate(Node.state.h,actn,Î±)
        #Node.state.Q = QUpdate(Node,actn,Î¼,Î±)
        if Node.state.name == "Î¾"
            Î¼ ? habitCtrl(Node.Î¼,data=data[3:4],Î±=Î±) : habitCtrl(Node.Î½,data=data[3:4],Î±=Î±)
        end
    end

    return Node, Rwd
end

function MFCtrl(Node::DecisionTree; data::Union{AbstractArray,Nothing}=Nothing(), Î±::Float64=0.5,Î¸::Float64=5.0)

    if typeof(data) == Nothing
        Ï€, a_idx = softMax([Node.state.Q.A1, Node.state.Q.A2],Î¸=Î¸)
        rv = rand()
        ((Ï€ >= rv && a_idx == 1) || (Ï€ < rv && a_idx == 2)) ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskEval(Node.state.name,actn)
        Node.state.R = Rwd
        Node.state.Q = QUpdate(Node,actn,Î¼,Î±)
        dat = actn
        if Node.state.name == "Î¾"
            Î¼ ? dat2=MFCtrl(Node.Î¼,Î±=Î±)[3] : dat2=MFCtrl(Node.Î½,Î±=Î±)[3]
            dat = actn, Î¼, dat2
        end
    else
        data[1] ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskRead(Node.state.name,data[1:2])
        Node.state.R = Rwd
        Node.state.Q = QUpdate(Node,actn,Î¼,Î±)

        if Node.state.name == "Î¾"
            Î¼ ? MFCtrl(Node.Î¼,data=data[3:4],Î±=Î±) : MFCtrl(Node.Î½,data=data[3:4],Î±=Î±)
        end
        dat=Nothing()
    end

    return Node, Rwd, dat
end

function MBCtrl(Node::DecisionTree; data::Union{AbstractArray,Nothing}=Nothing(), Î±::Float64=0.5,Î¸::Float64=5.0)
    if typeof(Node.state.T) == Nothing
        throw(error("Agent must have Transition modelling enabled, set kwarg \"TM=true\" when created"))
    end



    if typeof(data) == Nothing
        Ï€, a_idx = softMax([Node.state.Q.A1, Node.state.Q.A2],Î¸=Î¸)
        rv = rand()
        ((Ï€ >= rv && a_idx == 1) || (Ï€ < rv && a_idx == 2)) ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskEval(Node.state.name,actn)
        Node.state.R = Rwd
        Node.state.Q = modelledQUpdate(Node,actn,Î¼,Î±)

        if Node.state.name == "Î¾"
            Î¼ ? MBCtrl(Node.Î¼,Î±=Î±) : MBCtrl(Node.Î½,Î±=Î±)
        end
    else
        data[1] ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskRead(Node.state.name,data[1:2])
        Node.state.R = Rwd
        Node.state.Q = modelledQUpdate(Node,actn,Î¼,Î±)

        if Node.state.name == "Î¾"
            Î¼ ? MBCtrl(Node.Î¼,data=data[3:4],Î±=Î±) : MBCtrl(Node.Î½,data=data[3:4],Î±=Î±)
        end
    end


    return Node, Rwd
end

function GDCtrl(Node::DecisionTree; data::Union{AbstractArray,Nothing}=Nothing(), Î±::Float64=0.5, Î±â‚œ::Float64=0.1,Î¸::Float64=5.0)
    if typeof(Node.state.T) == Nothing
        throw(error("Agent must have Transition modelling enabled, set kwarg \"TM=true\" when created"))
    end

    if typeof(data) == Nothing
        Ï€, a_idx = softMax([Node.state.Q.A1, Node.state.Q.A2],Î¸=Î¸)
        rv = rand()
        ((Ï€ >= rv && a_idx == 1) || (Ï€ < rv && a_idx == 2)) ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskEval(Node.state.name,actn)

        Node.state.R = Rwd
        Node.state.Q = modelledQUpdate(Node,actn,Î¼,Î±)


        if Node.state.name == "Î¾"
            Î¼ ? GDCtrl(Node.Î¼,Î±=Î±) : GDCtrl(Node.Î½,Î±=Î±)
        end
    else

        data[1] ? actn = "A1" : actn = "A2"

        Î¼, Rwd = taskRead(Node.state.name,data[1:2])

        Node.state.R = Rwd
        Node.state.Q = modelledQUpdate(Node,actn,Î¼,Î±)


        if Node.state.name == "Î¾"
            Î¼ ? GDCtrl(Node.Î¼,data=data[3:4],Î±=Î±) : GDCtrl(Node.Î½,data=data[3:4],Î±=Î±)
        end
    end
        Node.state.T = transitionUpdate(Node,actn,Î¼,Î±â‚œ)
    return Node, Rwd
end

############## Functions that run a full Epoch of a Raw Controller ###############################
function runHabit(; agent::DecisionTree=buildAgent(2,hm=true), data::Union{AbstractArray,Nothing}=Nothing(), n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    if typeof(data) != Nothing
        n = length(data[:,1])
    end
    epoch_H = zeros(6,n)
    epoch_Q = zeros(6,n)
    Rwd = zeros(n)
    for i=1:n
        d = Nothing()
        if typeof(data) != Nothing
            d=data[i,:]
        end
        Rwd[i] = habitCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
        epoch_H[:,i] = [agent.state.h.A1, agent.state.h.A2, agent.Î¼.state.h.A1, agent.Î¼.state.h.A2, agent.Î½.state.h.A1, agent.Î½.state.h.A2]
        epoch_Q[:,i] = [agent.state.Q.A1, agent.state.Q.A2, agent.Î¼.state.Q.A1, agent.Î¼.state.Q.A2, agent.Î½.state.Q.A1, agent.Î½.state.Q.A2]
    end

    return agent,epoch_Q,Nothing(), epoch_H
end

function runMF(; agent::DecisionTree=buildAgent(2), data::Union{AbstractArray,Nothing}=Nothing(), n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0)
    if typeof(data) != Nothing
        n = length(data[:,1])
    end
    epoch_Q = zeros(6,n)
    Rwd = zeros(n)
    for i=1:n
        d = Nothing()
        if typeof(data) != Nothing
            d=data[i,:]
        end
        Rwd[i] = MFCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
        epoch_Q[:,i] = [agent.state.Q.A1, agent.state.Q.A2, agent.Î¼.state.Q.A1, agent.Î¼.state.Q.A2, agent.Î½.state.Q.A1, agent.Î½.state.Q.A2]
    end

    return agent, epoch_Q, Nothing(), Nothing()
end

function runMB(; agent::DecisionTree=buildAgent(2,TM=true), data::Union{AbstractArray,Nothing}=Nothing(), n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0, TM::AbstractArray = [0.7 0.7 1.0 1.0 1.0 1.0] )
    agent.state.T.A1, agent.state.T.A2, agent.Î¼.state.T.A1, agent.Î¼.state.T.A2, agent.Î½.state.T.A1, agent.Î½.state.T.A2 = TM[1], TM[2], TM[3], TM[4], TM[5], TM[6]
    if typeof(data) != Nothing
        n = length(data[:,1])
    end
    epoch_Q = zeros(6,n)
    epoch_T = zeros(6,n)
    Rwd = zeros(n)
    for i=1:n
        d = Nothing()
        if typeof(data) != Nothing
            d=data[i,:]
        end
        Rwd = MBCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
        epoch_Q[:,i] = [agent.state.Q.A1, agent.state.Q.A2, agent.Î¼.state.Q.A1, agent.Î¼.state.Q.A2, agent.Î½.state.Q.A1, agent.Î½.state.Q.A2]
        epoch_T[:,i] = [agent.state.T.A1, agent.state.T.A2, agent.Î¼.state.T.A1, agent.Î¼.state.T.A2, agent.Î½.state.T.A1, agent.Î½.state.T.A2]
    end

    return agent, epoch_Q, epoch_T, Nothing()
end

########### Functions that run Epochs of Models comprised of Multiple Controllers ##################
function runGD(; agent::DecisionTree=buildAgent(2,TM=true), data::Union{AbstractArray,Nothing}=Nothing(), n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    if typeof(data) != Nothing
        n = length(data[:,1])
    end
    epoch_Q = zeros(6,n)
    epoch_T = zeros(6,n)
    Rwd = zeros(n)
    for i=1:n
        d = Nothing()
        if typeof(data) != Nothing
            d=data[i,:]
        end
        Rwd = GDCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
        epoch_Q[:,i] = [agent.state.Q.A1, agent.state.Q.A2, agent.Î¼.state.Q.A1, agent.Î¼.state.Q.A2, agent.Î½.state.Q.A1, agent.Î½.state.Q.A2]
        epoch_T[:,i] = [agent.state.T.A1, agent.state.T.A2, agent.Î¼.state.T.A1, agent.Î¼.state.T.A2, agent.Î½.state.T.A1, agent.Î½.state.T.A2]
    end

    return agent, epoch_Q, epoch_T, Nothing()
end

function runHWV(; agent::DecisionTree=buildAgent(2,TM=true,hm=true), data::Union{AbstractArray,Nothing}=Nothing(), n::Int=1000, Î±::Float64=0.5, Î¸::Float64=5.0 )
    if typeof(data) != Nothing
        n = length(data[:,1])
    end
    # pre allocating data arrays
    epoch_Q = zeros(6,n)
    epoch_T = zeros(6,n)
    epoch_H = zeros(6,n)
    Rwd = zeros(n)

    #HWV.state.T.A1, HWV.state.T.A2, HWV.A1.state.T.A1, HWV.A1.state.T.A2, HWV.A2.state.T.A1, HWV.A2.state.T.A2 = 0.7, 0.7, 1.0, 1.0, 1.0, 1.0
    ## Param init conditions
    Pð‘® = ones(n)
    rð‘® = 0.0
    r0 = 0.0
    h_avg = 0.0

    for i=1:n
        Pð‘®[i] = 1/( 1 + exp(abs(rð‘® - r0) - abs(h_avg^2)) )
        d = Nothing()
        if typeof(data) != Nothing
            d=data[i,:]
        end

        if rand() < Pð‘®[i]
            Rwd = GDCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
            rð‘® = (1-Î±)*rð‘® + Î±*Rwd
        else
            Rwd = habitCtrl(agent,data=d,Î±=Î±,Î¸=Î¸)[2]
            h_avg = sum([agent.state.h.A1, agent.state.h.A2, agent.Î¼.state.h.A1, agent.Î¼.state.h.A2, agent.Î½.state.h.A1, agent.Î½.state.h.A2])/6
        end
        r0 = (1-Î±)*r0 + Î±*Rwd
        epoch_Q[:,i] = [agent.state.Q.A1, agent.state.Q.A2, agent.Î¼.state.Q.A1, agent.Î¼.state.Q.A2, agent.Î½.state.Q.A1, agent.Î½.state.Q.A2]
        epoch_T[:,i] = [agent.state.T.A1, agent.state.T.A2, agent.Î¼.state.T.A1, agent.Î¼.state.T.A2, agent.Î½.state.T.A1, agent.Î½.state.T.A2]
        epoch_H[:,i] = [agent.state.h.A1, agent.state.h.A2, agent.Î¼.state.h.A1, agent.Î¼.state.h.A2, agent.Î½.state.h.A1, agent.Î½.state.h.A2]
    end

    return agent, epoch_Q, epoch_T, epoch_H, Pð‘®
end
